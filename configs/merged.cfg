[paths]
vectors = null
init_tok2vec = null
vocab = null

[system]
gpu_allocator = null
seed = 0

[nlp]
lang = "fi"
pipeline = ["tok2vec","tagger","morphologizer","parser","attribute_ruler","lemmatizer","ner"]

[components]

[components.attribute_ruler]
source = "training/UD_Finnish-TDT/model-best/"

[components.lemmatizer]
source = "training/UD_Finnish-TDT/model-best/"

[components.morphologizer]
source = "training/UD_Finnish-TDT/model-best/"

[components.parser]
source = "training/UD_Finnish-TDT/model-best/"

[components.tagger]
source = "training/UD_Finnish-TDT/model-best/"

[components.tok2vec]
source = "training/UD_Finnish-TDT/model-best/"

[components.ner]
source = "training/turku-one/model-best/"

[initialize]
vectors = ${paths.vectors}
init_tok2vec = ${paths.init_tok2vec}
vocab_data = ${paths.vocab}
lookups = null
before_init = null
after_init = null

[initialize.components]

[initialize.tokenizer]
